---
title: "Reversal Data Cleaning and Diagnostics - Old"
author: "Sophie Paolizzi"
date: "9/20/2021"
output: html_document
---
### Serial Reversal Learning Task (SRLT) 

The SRLT builds on established reversal paradigms (Costa et al., 2015; Dombrovski et al., 2010). In this task, participants select between two random stimuli in three 80-trial blocks, for a total of 240 trials. After participants make their choice, feedback appears on the screen related to whether their choice was correct or incorrect (Figure 1). Each block is made up of an acquisition and reversal for three separate stimulus pairings. In the initial acquisition phase, a given stimulus is associated with “correct” feedback 80% and “incorrect” feedback 20% of the time, while the other is incorrect feedback 80% and correct feedback 20% of the time. In the reversal phase, contingencies are reversed such that the previously predominantly rewarding stimulus is now the less rewarding option. Participants learn these contingencies about the same two stimuli for one acquisition and one reversal phase before two new stimuli are presented. Data for this task were collected using the stimulus presentation software Inquisit.


### Data Cleaning
The current cleaning code is housed in the Tidy_functions_PUBS script: refer to these functions for any questions about data cleaning. For any questions related to the definition of task variables, refer to: https://docs.google.com/spreadsheets/d/1V2UD28C_zAfH90BnNO3si6c0-qDUDFbHoU44rfdEt4I/edit#gid=1309555968. 

 *Load Pilot Data...*

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
options(knitr.duplicate.label = "allow")
##Load Packages and source scripts
pacman::p_load(tidyverse, readr, janitor, ggplot2,wesanderson, cowplot, flextable, plotly, emmeans, data.table)
setwd("~/github_repos/PUBS_Data_Verification/")
source("Tidy_functions_PUBS.R")
#reversal_data_8.16 <- data.table::fread("~/github_repos/ReversalTask/Reversal_pilot_mTurk.csv", fill = TRUE)
#load data
#load("Reversal_Task_Cleaned.Rdata")
reversal_data <- data.table::fread("~/github_repos/ReversalTask/Reversal_pilot_mTurk.csv", fill = TRUE) %>% group_by(subject) %>% filter(n() >= 200)

reversal_data <- reversal_data %>% mutate(subject = ifelse(time == 18:47:13, 456, subject))

```

*Clean and transform Data...*
```{r}
reversal <- tidy_reversal(reversal_data)
```


```{r, include=FALSE}

reversal <- create_vars_reversal(reversal)
```

*Only retain distinct trials...*

```{r, include=FALSE}
by_block_phase <- reversal %>% group_by(subject, block_number, task_phase) %>%
  summarise(avg_latency = mean(as.numeric(trial_latency)),
            reached_criterion = min(reached_criterion, na.rm=TRUE),
            Consecutive_Correct = max(ConsecutiveCorrect),
            percent_correct_phase = max(percent_correct_phase),
            NumberofTrials = max(trial_number))%>%
  mutate(above_threshold = ifelse(reached_criterion >= 10, "Above", "Below")) 

by_block <- reversal %>% group_by(subject, block_number) %>%
  summarise(avg_latency = mean(as.numeric(trial_latency)),
            reached_criterion = min(reached_criterion, na.rm=TRUE),
            percent_correct_phase = max(numbercorrect)/50,
            reversal_number = (max(reversalnumber)),
            NumberofTrials = max(trial_number))%>%
  mutate(above_threshold = ifelse(percent_correct_phase >= .50, "Above", "Below")) 


by_phase <- reversal %>% group_by(subject, task_phase) %>%
  summarise(avg_latency = mean(as.numeric(trial_latency)),
            reached_criterion = min(reached_criterion, na.rm=TRUE),
            percent_correct_phase = mean(percent_correct_phase),
            NumberofTrials_Phase = max(phase_trialnum))%>%
  mutate(above_threshold = ifelse(percent_correct_phase >= .50, "Above", "Below")) 

stats <- colMeans(by_block[sapply(by_block, is.numeric)])
by_block <- rbind(by_block, stats)
by_block$subject[41] <- "Means"


stats <- colMeans(by_phase[sapply(by_phase, is.numeric)])
by_phase <- rbind(by_phase, stats)
by_phase$subject[21] <- "Means"


stats <- colMeans(by_block_phase[sapply(by_block_phase, is.numeric)])
by_block_phase <- rbind(by_block_phase, stats)
by_block_phase$subject[81] <- "Means"

#save(distinct, by_block_phase, file = "Reversal_Task_Cleaned.Rdata")
```

### Pilot Results

**Table 1**. Performance statistics were calculated by block (1,2, or 3), and phase (acquisition or reversal). . Problematic rows are highlighted yellow. 

Avg_latency:
Reached_Criterion:
Percent_Correct_Phase;
Consecutive-Correct:
Number_Correct:
Numberoftrials_phase: number of trials 
Above_threshold: all white blocks cleared the threshold of performing better than chance accuracy (>50% correct). 


All participants cleared the first criterion of making at least 10 "correct choices" per block (reached_criterion). Data were flagged as "Below Threshold" if participants chose the "correct" option less than 50% of the time in any given phase (percent_correct_phase). The maximum number of consecutive "correct" choices participants made were also recorded: only 1 participant in 1 block made less than 8 consecutive correct choices.


```{r,echo=FALSE}
subjects <- as.character(unique(reversal$subject)); cowplot_list <- list(); plot_subjects <- list()
colormatrix <- ifelse(by_block_phase$above_threshold == "Below", wes_palette("Cavalcanti1")[c(1)], "white") ##potentially save these as bad_blocks vector
tab <- by_block_phase %>% flextable() %>% flextable::bg(j = 1:8, bg=colormatrix)
reversal_earnings <- reversal %>% group_by(subject) %>% summarize(cents_earned = max(totalearnings)) %>% dplyr::rename(centsearned_r = cents_earned)
save(reversal_earnings, file = "Payment/Reversal.Rdata")

sink("/dev/null")
tab
sink(); 
```
```{r}
##N.B. For actual analysis, hang here and create drop_irregular function that prints summaries and has options to get rid of:
## bad subjects (those with < avg accuracy overall)
##bad blocks (blocks with <50% accuracy)
##bad trials (latency > 3000 - this should also encompass noresponse)
```


**Figure 1**. This chunk prints an overall view of reaction time. 
```{r}
rts <- list()
for (i in subjects) {
  s <- reversal %>% dplyr::filter(subject == i)
rt_hist <- ggplot(s, aes(trial_latency), stat = "bin") + geom_histogram() + ggtitle(i)
rts[[i]] <- rt_hist
}

rts[[length(rts) + 1]] <- rt_hist <- ggplot(reversal, aes(trial_latency), stat = "bin") + geom_histogram() + ggtitle("Overall RTs")
rts[length(rts)]
```


## Summary of Reversal Findings {.tabset}
```{r}

template <- c(
    "### rts {{y}}\n",
    "```{r, echo = FALSE}\n",
    "rts[[{{y}}]] \n",
    "```\n",
    "\n"
  )

plots <- lapply(1:length(rts), function(y) {knitr::knit_expand(text = template)})

```



`r knitr::knit(text = unlist(plots))`
```{r, message = 'hide'}
for (i in subjects) {
  d <- reversal %>% dplyr::filter(subject == i)
  scatter <- ggplot(d, aes(x=trial_number, y= trial_response, color = as.factor(isResponse_num))) +
     geom_point() +
     geom_vline(aes(xintercept = reversal_trial, color = "Reversal Point")) +
     scale_color_manual(labels = c("Incorrect", "Correct", "Reversal Point"),
                        values = (wes_palette("Cavalcanti1")[c(5,4,2)])) + 
     xlab("Trial Number") + ylab("Response Type") + ggtitle(i) +
     facet_wrap(~block_number)
  scatter[[i]] <- scatter
h <- by_block_phase %>% filter(subject == i) %>% group_by(task_phase)
hist <- ggplot(h, aes(y=percent_correct_phase, x = task_phase, fill = above_threshold)) +
  geom_bar(stat = "identity") + 
  scale_fill_manual(values = (wes_palette("Cavalcanti1")[c(4,5)])) + 
 ylab("Percentage Correct") + xlab("") +  facet_grid(~ block_number)
 hist[[i]] <- hist
 plot_subjects[[i]] <- list(scatter, hist) 
 
 cowplot <- cowplot::plot_grid(scatter, hist, nrow = 2)
 cowplot_list[[i]] <- cowplot
}
```


## Summary of Reversal Findings {.tabset}
```{r}

template <- c(
    "### cowplot_list {{y}}\n",
    "```{r, echo = FALSE}\n",
    "cowplot_list[[{{y}}]] \n",
    "```\n",
    "\n"
  )

plots <- lapply(1:length(cowplot_list), function(y) {knitr::knit_expand(text = template)})

```



`r knitr::knit(text = unlist(plots))`

## Hisotry of MD Changes {.tabset}
#### Pilot Findings Summary 
On average, participants made the "correct" choice approximately 80% of the time, and made at least 10 correct choices by trial 17. Both of these outcomes suggest the block length can be shortened as suggested by MNH to as little as 50 trials. Regarding data verification and visualization, it will be important to look at RT data more explicitly in the larger sample. Based on the pilot, it looks like it could be handled pretty easily with a log or invesrse transform. 

### Task Reccomendations - For Michael Discussion
1. Block length to 50 trials per MNH's suggestion. Given subjects learned the contingencies in an average of 16 trials, this seems about correct. For time's sake, I'm thinking of erring on the side of 4 blocks of 50 trials. 
2. Explicitly instruct participants to click as quickly and accurately as possible, and shorten response windows such that the entire task will take between 8 and 10 minutes. See "Task Timing" for more details.  https://docs.google.com/spreadsheets/d/1V2UD28C_zAfH90BnNO3si6c0-qDUDFbHoU44rfdEt4I/edit#gid=390744519 
3. Combine stimulus selection and feedback phases, to save time?
4. Collect 10-15 subjects and check for final timing.

### Data Check Plans - For Michael Discussion 8/26

1. Translate dplyr operations into usable functions and try to duplicate as little as possible across tasks.  
2. drop_irregular function
3. Check RTs and provide info on possible transforms
4. 
