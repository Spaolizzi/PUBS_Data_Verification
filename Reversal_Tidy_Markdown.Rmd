---
title: "Reversal Data Cleaning and Diagnostics"
author: "Sophie Paolizzi"
date: "8/3/2021"
output: html_document
---
### Serial Reversal Learning Task (SRLT) 

The SRLT builds on established reversal paradigms (Costa et al., 2015; Dombrovski et al., 2010). In this task, participants select between two random stimuli in three 80-trial blocks, for a total of 240 trials. After participants make their choice, feedback appears on the screen related to whether their choice was correct or incorrect (Figure 1). Each block is made up of an acquisition and reversal for three separate stimulus pairings. In the initial acquisition phase, a given stimulus is associated with “correct” feedback 80% and “incorrect” feedback 20% of the time, while the other is incorrect feedback 80% and correct feedback 20% of the time. In the reversal phase, contingencies are reversed such that the previously predominantly rewarding stimulus is now the less rewarding option. Participants learn these contingencies about the same two stimuli for one acquisition and one reversal phase before two new stimuli are presented. Data for this task were collected using the stimulus presentation software Inquisit.

### Pilot Data
#### TL;DR for Data Cleaning
This final dataframe resulting from this cleaning was used to re-program data structure from the task, so the current cleaning code will be updated, so the current cleaning code does not need to be reviewed unless you suspect anaomalies in the resulting dataframe. For any questions related to the definition of task variables, please refer to: https://docs.google.com/spreadsheets/d/1V2UD28C_zAfH90BnNO3si6c0-qDUDFbHoU44rfdEt4I/edit#gid=1309555968. Skip to heading **Pilot Results** for information on pilot data. 

 *Load Pilot Data...*

```{r setup, message=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
##Load Packages and source scripts
pacman::p_load(tidyverse, readr, janitor, ggplot2,wesanderson, cowplot, flextable, emmeans)
setwd("~/github_repos/PUBS_Data_Verification/")
#load data
#load("Reversal_Task_Cleaned.Rdata")

```

*Clean and transform Data...*

```{r, include=FALSE}
reversal_data <- data.table::fread("pubs_pilot_reversal_task_forpilot_7.4.21_raw_21_07_29.csv", fill = TRUE) %>% row_to_names(4) %>% group_by(subject) %>% filter(n() >= 200)
#drop rows that aren't useful - will delete from main script
reversal_data <- reversal_data %>% select(!c(practiceInstructionIndex,blockName,ITI, numTrialEachBlock, instructionIndex, isThisTrialPractice, trialCounter, blockNumber, build, experimentName,picture.Left.currentvalue, picture.Right.currentvalue))

##long pipe for tidying data, not by block
distinct <- reversal_data %>%
  group_by(subject, block_number, trial_number) %>% ##group by subject and block to prevent weirdness
  mutate(trial_number = as.numeric(trial_number)) %>% mutate(block_number = as.numeric(block_number)) %>% mutate(reversalnumber = as.numeric(reversalnumber)) %>% ##change needed things to numeric
  arrange(subject, block_number, trial_number) %>% slice(which.max(centsearned)) %>% ## arrange in order based on grouping
  mutate(trial_latency = ifelse(rightleft == "left", as.numeric(trial.presentation_left.latency), as.numeric(trial.presentation_right.latency))) %>% ## combine latencies to create overall trial latency
  mutate(trial_response = ifelse(rightleft == "left", trial.presentation_left.response, trial.presentation_right.response)) %>% ## combine responses to create overall trial response
  mutate(trial_response = ifelse(trial_response == 45, "left", trial_response)) %>% mutate(trial_response = ifelse(trial_response == 50, "right", trial_response)) %>% mutate(trial_response = ifelse(trial_response == 0, "noresponse", trial_response)) %>% #change name of response variable
  mutate(total_trialnum = ifelse(block_number > 1, trial_number + (80*(block_number-1)), trial_number)) %>% #add running counter for total trials
  mutate(reversal_trial = ifelse(trial_number == reversalnumber , trial_number, NA)) %>% #change name of response variable
  select(!c(trial.presentation_left.latency, trial.presentation_right.latency, trial.presentation_left.response, trial.presentation_right.response)) %>% # delete extra columns for conciseness
  filter(!total_trialnum > 240 && !block_number > 3) %>% filter(!trial_number == 0) %>% #removing things we don't need
  group_by(subject, block_number) %>% mutate(percent_correct_block = as.numeric(numbercorrect)/80) %>% ##percentage correct across block
  mutate(task_phase = ifelse(trial_number <= reversalnumber, "Acquisition", "Reversal")) #note which block they're in
```

*Only retain distinct trials...*

```{r, include=FALSE}

distinct <- distinct %>% group_by(subject, block_number, task_phase) %>% #grouping again
  mutate(numbercorrect = as.numeric(numbercorrect)) %>% # get things as.numeric
  mutate(phase_trialnum = ifelse(task_phase == "Reversal", cumsum(task_phase == "Reversal"), cumsum(task_phase == "Acquisition"))) %>%  ## number of trials since reversal
  mutate(numbercorrect_phase = ifelse(task_phase == "Reversal", cumsum(isResponseCorrect == 1), cumsum( isResponseCorrect == 1))) %>% ## number of correct choices by phase
  mutate(ResponseCorrect = as.numeric(isResponseCorrect)) %>% ## transform to numeric
  mutate(reached_criterion = ifelse(as.numeric(numbercorrect_phase) > 10, phase_trialnum, NA)) %>% ## did subjects get 10 consecutive answers correct
  mutate(percent_correct_phase = as.numeric(numbercorrect_phase)/max(as.numeric(phase_trialnum)))  %>% # percent of correct choices by phase (acquisiton or reversal)
  mutate(diff_numbercorrect_phase = numbercorrect_phase - lag(numbercorrect_phase)) %>%
   ungroup() %>%
  group_by(subject, task_phase, block_number, grp = lag(cumsum(isResponseCorrect == -1), default = 0)) %>%
  mutate(ConsecutiveCorrect = ifelse(isResponseCorrect == -1, 0, cumsum(isResponseCorrect))) %>%
  mutate(ConsecutiveCorrect = ifelse(isResponseCorrect == 0, NA, ConsecutiveCorrect)) %>%
  ungroup() %>% select(-grp)

obj <- distinct %>% group_by(subject, block_number, task_phase) %>%
  summarise(avg_latency = mean(as.numeric(trial_latency)),
            reached_criterion = min(reached_criterion, na.rm=TRUE),
            percent_correct_phase = max(percent_correct_phase),
            Consecutive_Correct = max(ConsecutiveCorrect),
            NumberofTrials_Phase = max(phase_trialnum)) %>%
  mutate(above_threshold = ifelse(percent_correct_phase >= .50, "Above", "Below"))

stats <- colMeans(obj[sapply(obj, is.numeric)])

obj <- rbind(obj, stats)
obj$subject[31] <- "Means"

#save(distinct, obj, file = "Reversal_Task_Cleaned.Rdata")
```

### Pilot Results

**Table 1**. Performance statistics were calculated by block (1,2, or 3) and phase (acquisition or reversal). All participants cleared the first criterion of making at least 10 "correct choices" per block (reached_criterion). Data were flagged as "Below Threshold" if participants chose the "correct" option less than 50% of the time in any given phase (percent_correct_phase). The maxiumum number of consecutive "correct" choices participants made were also recorded: only 1 participant in 1 block made less than 8 consecutive correct choices.


```{r,echo=FALSE}
subjects <- unique(distinct$subject); cowplot_list <- list(); plot_subjects <- list()
colormatrix <- ifelse(obj$above_threshold == "Below", wes_palette("Cavalcanti1")[c(1)], "white") ##potentially save these as bad_blocks vector
tab <- obj %>% flextable() %>% bg(j = 1:9, bg=colormatrix)

sink("/dev/null")
tab
sink(); 
```
```{r}
##N.B. For actual analysis, hang here and create drop_irregular function that prints summaries and has options to get rid of:
## bad subjects (those with < avg accuracy overall)
##bad blocks (blocks with <50% accuracy)
##bad trials (latency > 3000 - this should also encompass noresponse)
```


**Figure 1**. Rough look at reaction time. The distribution looks about correct: For eventual analysis, We will like drop trials with no response. 
```{r}
hist(distinct$trial_latency)

```


**Figures 2a-e**. Further elaborating from Table 1. It does appear that subjects who had a tendency not to respond often did worse on the benchmarks above. It may be work adding a check on whether participants are responding (or the percentage of trials they responded on). Similarly, it looks as though longer RTs are correlated with worse performance. It may be worth adding an explicit instruction for participants to respond as quickly and accurately as possible. This should also speed up the task considerably. 


```{r, message = 'hide'}
for (i in subjects) {
  
  scatter <- ggplot(distinct %>% dplyr::filter(subject == i), aes(x=trial_number, y=trial_response, colour = isResponseCorrect)) + 
     geom_point() + 
     geom_vline(aes(xintercept = reversal_trial, color = "Reversal Point")) + 
     scale_color_manual(labels = c("Incorrect", "Correct", "Reversal Point"),values = (wes_palette("Cavalcanti1")[c(5,4,2)])) + 
     xlab("Trial Number") + ylab("Response Type") + ggtitle(i) +
     facet_wrap(~block_number)
  scatter[[i]] <- scatter

hist <- obj %>% filter(subject == i) %>% group_by(block_number) %>% ggplot(aes(y=percent_correct_phase, x = task_phase, fill = above_threshold)) +
  geom_bar(stat = "identity") + 
  scale_fill_manual(values = (wes_palette("Cavalcanti1")[c(4,5)])) + 
 ylab("Percentage Correct") + xlab("") +  facet_grid(~ block_number)
 hist[[i]] <- hist
 plot_subjects[[i]] <- list(scatter, hist) 
 
 cowplot <- cowplot::plot_grid(scatter, hist, nrow = 2)
 cowplot_list[[i]] <- cowplot
}

sink("/dev/null")
cowplot_list
sink(); 
```

#### Pilot Findings Summary 
On average, participants made the "correct" choice approximately 80% of the time, and made at least 10 correct choices by trial 17. Both of these outcomes suggest the block length can be shortened as suggested by MNH to as little as 50 trials. Regarding data verification and visualization, it will be important to look at RT data more explicitly in the larger sample. Based on the pilot, it looks like it could be handled pretty easily with a log or invesrse transform. 

### Task Reccomendations - For Michael Discussion
1. Block length to 50 trials per MNH's suggestion. Given subjects learned the contingencies in an average of 16 trials, this seems about correct. For time's sake, I'm thinking of erring on the side of 4 blocks of 50 trials. 
2. Explicitly instruct participants to click as quickly and accurately as possible, and shorten response windows such that the entire task will take between 8 and 10 minutes. See "Task Timing" for more details.  https://docs.google.com/spreadsheets/d/1V2UD28C_zAfH90BnNO3si6c0-qDUDFbHoU44rfdEt4I/edit#gid=390744519 
3. Combine stimulus selection and feedback phases, to save time?
4. Collect 10-15 subjects and check for final timing.

### Data Check Plans - For Michael Discussion 8/26

1. Translate dplyr operations into usable functions and try to duplicate as little as possible across tasks.  
2. drop_irregular function
3. Check RTs and provide info on possible transforms
4. 
